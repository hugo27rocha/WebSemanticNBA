{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project â€“ Phase 2 Group 07 Hugo Rocha\n",
    "\n",
    "In this part it was transformed some data before being loaded by adding a known vocabularies FOAF. And it was enriched the triplestore with external data from dbpedia.\n",
    "\n",
    "Finaly it was defined the RDFS and RDFS+ rules\n",
    "\n",
    "For this part of the project it was decided that the examples were reduced to 50 per csv file for the turtle file to occupy less memory\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from csv import DictReader\n",
    "from rdflib import Dataset, URIRef, Literal, Namespace, RDF, RDFS, OWL, XSD, Graph\n",
    "from rdflib import Graph, URIRef, RDF, Literal\n",
    "from rdflib.namespace import FOAF, XSD, RDFS\n",
    "import pandas as pd\n",
    "from iribaker import to_iri"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Players"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('players.csv')\n",
    "data[\"player_id\"]  = data['PLAYER_ID'].apply(lambda x: str(x))\n",
    "data[\"season\"]  = data['SEASON'].apply(lambda x: str(x))\n",
    "data[\"roster_id\"] = data[\"player_id\"]  + \"_\" + data[\"season\"]\n",
    "del data[\"player_id\"]\n",
    "del data[\"season\"]\n",
    "\n",
    "#NEW only get 50 players (just for the example of the project)\n",
    "data = data.head(50)\n",
    "data.to_csv('players.csv')\n",
    "\n",
    "pls = Namespace(\"http://www.di.fc.ul.pt/~nba/player#\")\n",
    "tms = Namespace(\"http://www.di.fc.ul.pt/~nba/team#\")\n",
    "gms = Namespace(\"http://www.di.fc.ul.pt/~nba/games#\")\n",
    "foaf = Namespace(\"http://xmlns.com/foaf/0.1/\")\n",
    "dbp = Namespace(\"http://dbpedia.org/resource/\")\n",
    "owl = Namespace(\"http://www.w3.org/2002/07/owl#\")\n",
    "schema = Namespace(\"http://schema.org/\")\n",
    "\n",
    "graph=Graph()\n",
    "graph.bind(\"tms\", tms)\n",
    "graph.bind(\"pls\", pls)\n",
    "graph.bind(\"foaf\", FOAF)\n",
    "graph.bind(\"dbp\", dbp)\n",
    "graph.bind(\"owl\", OWL)\n",
    "graph.bind(\"gms\", gms)\n",
    "graph.bind(\"schema\", schema)\n",
    "\n",
    "\n",
    "team_file = \"players.csv\"\n",
    "with open(team_file,'r') as csvfile:\n",
    "    players_contents = [{k: v for k, v in row.items()}\n",
    "        for row in csv.DictReader(csvfile, skipinitialspace=True, quotechar='\"', delimiter=',')]\n",
    "\n",
    "for p in players_contents:\n",
    "    rid = URIRef(pls+p[\"roster_id\"])\n",
    "    pid = URIRef(pls+p[\"PLAYER_ID\"])\n",
    "    tid  = URIRef(tms+p[\"TEAM_ID\"])\n",
    "    Season=Literal(p[\"SEASON\"],datatype=XSD.int)\n",
    "     \n",
    "    #NEW \n",
    "    #adding known vocabularies FOAF    \n",
    "    graph.add((rid, RDF.type, FOAF.Person))\n",
    "    player_name =  Literal(p[\"PLAYER_NAME\"], lang='en') \n",
    "    graph.add((rid, FOAF.name, player_name))\n",
    "    \n",
    "    #Enrich triplestore with external data from dbpedia\n",
    "    dbp_resourse = URIRef(to_iri(dbp+p[\"PLAYER_NAME\"])) \n",
    "    graph.add((rid, RDF.type, dbp_resourse))\n",
    "    \n",
    "    graph.add((rid, RDF.type, pls.Player))\n",
    "    graph.add((rid, pls.player_id, pid))\n",
    "    graph.add((rid, tms.playsIn, tid))\n",
    "    graph.add((rid, pls.season, Season))\n",
    "    graph.add((rid, pls.Name, dbp_resourse))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TEAMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "team_file = \"teams.csv\"\n",
    "with open(team_file,'r') as csvfile:\n",
    "    team_contents = [{k: v for k, v in row.items()}\n",
    "        for row in csv.DictReader(csvfile, skipinitialspace=True, quotechar='\"', delimiter=',')]\n",
    "\n",
    "tms = Namespace(\"http://www.di.fc.ul.pt/~nba/team#\")\n",
    "graph.bind(\"tms\", tms)\n",
    "\n",
    "for s in team_contents:\n",
    "    tid= URIRef(tms+s[\"TEAM_ID\"])\n",
    "    lid= URIRef(tms+s[\"LEAGUE_ID\"])\n",
    "    Min_year=Literal(s[\"MIN_YEAR\"],datatype=XSD.int)\n",
    "    Max_year=Literal(s[\"MAX_YEAR\"],datatype=XSD.int)\n",
    "    abre = Literal(s['ABBREVIATION'], datatype=XSD['string'])\n",
    "    nick = URIRef(to_iri(tms+s[\"NICKNAME\"]))\n",
    "    nick_name =  Literal(s[\"NICKNAME\"], lang='en')\n",
    "    year_f=Literal(s[\"YEARFOUNDED\"],datatype=XSD.int)\n",
    "    arenacapacity=Literal(s[\"ARENACAPACITY\"],datatype=XSD.int)\n",
    "    \n",
    "    #NEW\n",
    "    #adding known vocabularies FOAF\n",
    "    graph.add((tid, FOAF.name, Literal(s[\"CITY\"] + '_' +s[\"NICKNAME\"], lang=\"en\")))\n",
    "    \n",
    "    #Enrich triplestore with external data from dbpedia\n",
    "    dbp_resourse = URIRef(to_iri(dbp+s[\"CITY\"] + '_' +s[\"NICKNAME\"])) \n",
    "    graph.add((tid, RDF.type, dbp_resourse))\n",
    "    \n",
    "    Arena_dbp = URIRef(to_iri(dbp+s[\"ARENA\"])) \n",
    "    graph.add((tid, tms.arena, Arena_dbp))\n",
    "    \n",
    "    City_dbp = URIRef(to_iri(dbp+s[\"CITY\"])) \n",
    "    graph.add((tid, tms.city, City_dbp))\n",
    "    \n",
    "    Nick_dbp = URIRef(to_iri(dbp+s[\"NICKNAME\"])) \n",
    "    graph.add((tid, tms.nickname, Nick_dbp))\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    graph.add((tid, RDF.type, tms.Team))\n",
    "    graph.add((tid, tms.team_id, tid))\n",
    "    graph.add((tid, tms.league, lid))\n",
    "    graph.add((tid, tms.min_year, Min_year))\n",
    "    graph.add((tid, tms.max_year, Max_year))\n",
    "    graph.add((tid, tms.abbreviation, abre))\n",
    "    graph.add((tid, tms.year_found, year_f))\n",
    "    graph.add((tid, tms.arena_capacity, arenacapacity))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('ranking.csv')\n",
    "data[\"team_idd\"]  = data['TEAM_ID'].apply(lambda x: str(x))\n",
    "data[\"date\"]  = data['STANDINGSDATE'].apply(lambda x: str(x))\n",
    "data[\"ranking_id\"] = data[\"team_idd\"]  + \"_\"+ data[\"date\"]\n",
    "del data[\"team_idd\"]\n",
    "del data[\"date\"]\n",
    "data = data.head(50)\n",
    "data.to_csv('ranking.csv')\n",
    "\n",
    "\n",
    "rks = Namespace(\"http://www.di.fc.ul.pt/~nba/ranking#\")\n",
    "graph.bind(\"rks\", rks)\n",
    "\n",
    "rank_file = \"ranking.csv\"\n",
    "with open(rank_file,'r') as csvfile:\n",
    "    ranking_contents = [{k: v for k, v in row.items()}\n",
    "        for row in csv.DictReader(csvfile, skipinitialspace=True, quotechar='\"', delimiter=',')]\n",
    "\n",
    "\n",
    "for r in ranking_contents:\n",
    "       \n",
    "    rank_id = URIRef(rks+r[\"ranking_id\"])\n",
    "    tid= URIRef(tms+r[\"TEAM_ID\"]) \n",
    "    Season=Literal(r[\"SEASON_ID\"],datatype=XSD.int)\n",
    "    Date=Literal(r[\"STANDINGSDATE\"],datatype=XSD.date)\n",
    "    Games=Literal(r[\"G\"],datatype=XSD.int)\n",
    "    Wins=Literal(r[\"W\"],datatype=XSD.int)\n",
    "    Loses=Literal(r[\"L\"],datatype=XSD.int)\n",
    "    WL=Literal(r[\"W_PCT\"],datatype=XSD.decimal)\n",
    "    \n",
    "    #NEW\n",
    "    conference_dbp = URIRef(to_iri(dbp+r[\"CONFERENCE\"]))\n",
    "    graph.add((rank_id, rks.Conference, conference_dbp))\n",
    "    team_dbp = URIRef(to_iri(dbp+r[\"TEAM\"])) \n",
    "    graph.add((rank_id, rks.Team, team_dbp))\n",
    "    \n",
    "    \n",
    "    graph.add((rank_id, RDF.type, rks.Ranking))\n",
    "    graph.add((rank_id, tms.team_ranking, tid))\n",
    "    graph.add((rank_id, rks.season, Season))\n",
    "    graph.add((rank_id, rks.date, Date))\n",
    "    graph.add((rank_id, rks.games, Games))\n",
    "    graph.add((rank_id, rks.wins, Wins))\n",
    "    graph.add((rank_id, rks.loses, Loses))\n",
    "    graph.add((rank_id, rks.W_PCT, WL))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Game Details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdt = Namespace(\"http://www.di.fc.ul.pt/~nba/games_details#\")\n",
    "graph.bind(\"gdt\", gdt)\n",
    "\n",
    "data = pd.read_csv('games_details.csv')\n",
    "\n",
    "data[\"game_id\"]  = data['GAME_ID'].apply(lambda x: str(x))\n",
    "data[\"player_id\"]  = data['PLAYER_ID'].apply(lambda x: str(x))\n",
    "data[\"player_game\"] = data[\"game_id\"]  + \"_\" + data[\"player_id\"]\n",
    "del data[\"game_id\"]\n",
    "del data[\"player_id\"]\n",
    "data = data.head(50)\n",
    "data.to_csv('games_details.csv')\n",
    "\n",
    "rank_file = \"games_details.csv\"\n",
    "with open(rank_file,'r') as csvfile:\n",
    "    game_details_contents = [{k: v for k, v in row.items()}\n",
    "        for row in csv.DictReader(csvfile, skipinitialspace=True, quotechar='\"', delimiter=',')]\n",
    "\n",
    "\n",
    "for g in game_details_contents:\n",
    "       \n",
    "    player_game_id = URIRef(gdt+g[\"player_game\"])\n",
    "    gid= URIRef(gms+g[\"GAME_ID\"]) \n",
    "    tid= URIRef(tms+g[\"TEAM_ID\"]) \n",
    "    abre = Literal(g['TEAM_ABBREVIATION'], datatype=XSD['string'])\n",
    "    pid= URIRef(pls+g[\"PLAYER_ID\"])  \n",
    "       \n",
    "    #NEW \n",
    "    player_name =  Literal(g[\"PLAYER_NAME\"], lang='en') \n",
    "    graph.add((player_game_id, FOAF.name, player_name))\n",
    "    dbp_resourse = URIRef(to_iri(dbp+g[\"PLAYER_NAME\"])) \n",
    "    graph.add((player_game_id, pls.Name, dbp_resourse))\n",
    "    City_dbp = URIRef(to_iri(dbp+g[\"TEAM_CITY\"]))\n",
    "    graph.add((player_game_id, tms.city, City_dbp))\n",
    "    \n",
    "    graph.add((player_game_id, RDF.type, gdt.Game_Details))\n",
    "    graph.add((player_game_id, gms.game, gid))\n",
    "    graph.add((player_game_id, tms.team, tid))\n",
    "    graph.add((player_game_id, tms.abbreviation, abre))\n",
    "    graph.add((player_game_id, pls.player_id, pid))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GAMES \n",
    "nothing was altered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('games.csv')\n",
    "data = data.head(50)\n",
    "data.to_csv('games.csv')\n",
    "\n",
    "gms = Namespace(\"http://www.di.fc.ul.pt/~nba/games#\")\n",
    "graph.bind(\"gms\", gms)\n",
    "\n",
    "rank_file = \"games.csv\"\n",
    "with open(rank_file,'r') as csvfile:\n",
    "    game_contents = [{k: v for k, v in row.items()}\n",
    "        for row in csv.DictReader(csvfile, skipinitialspace=True, quotechar='\"', delimiter=',')]\n",
    "\n",
    "     \n",
    "for g in game_contents:\n",
    "       \n",
    "    game_id = URIRef(gms+g[\"GAME_ID\"])  \n",
    "    Game_Date=Literal(g[\"GAME_DATE_EST\"],datatype=XSD.date)\n",
    "    Season=Literal(g[\"SEASON\"],datatype=XSD.int)\n",
    "    Home= URIRef(tms+g[\"HOME_TEAM_ID\"]) \n",
    "    Visitor= URIRef(tms+g[\"VISITOR_TEAM_ID\"])\n",
    "    points_home=Literal(g[\"PTS_home\"],datatype=XSD.int)\n",
    "    points_away=Literal(g[\"PTS_away\"],datatype=XSD.int)\n",
    "    \n",
    "    graph.add((game_id, RDF.type, gms.Game))\n",
    "    graph.add((game_id, gms.game_id, game_id))\n",
    "    graph.add((game_id, gms.date, Game_Date))\n",
    "    graph.add((game_id, gms.season, Season))\n",
    "    graph.add((game_id, tms.home_team, Home))\n",
    "    graph.add((game_id, tms.visitor_team, Visitor))\n",
    "    graph.add((game_id, gms.Points_home, points_home))\n",
    "    graph.add((game_id, gms.Points_away, points_away))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RDFS and RDFS+ rules\n",
    "Some rules that were possible to define"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PLAYER\n",
    "graph.add((pls.Player, RDFS.subClassOf, FOAF.Person))\n",
    "graph.add((pls.Player, RDFS.subClassOf, schema.athlete))\n",
    "\n",
    "#TEAM\n",
    "graph.add((tms.Team, RDFS.subClassOf, schema.SportsTeam))\n",
    "\n",
    "#PlaysIn->Team\n",
    "graph.add((tms.playsIn, RDFS.domain, pls.Player))\n",
    "graph.add((tms.playsIn, RDFS.range, tms.Team))\n",
    "graph.add((tms.playsIn, RDF.type, RDF.Property))\n",
    "graph.add((tms.playsIn, OWL.inverseOf, tms.playedBy))\n",
    "\n",
    "\n",
    "#team_ranking->RANKING\n",
    "graph.add((tms.team_ranking, RDFS.domain, rks.Ranking))\n",
    "graph.add((tms.team_ranking, RDFS.range, tms.Team))\n",
    "graph.add((tms.team_ranking, RDF.type, RDF.Property))\n",
    "\n",
    "#home_team->Games\n",
    "graph.add((tms.home_team, RDFS.domain, gms.Game))\n",
    "graph.add((tms.home_team, RDFS.range, tms.Team))\n",
    "graph.add((tms.home_team, RDF.type, RDF.Property))\n",
    "\n",
    "#visitor_team->Games\n",
    "graph.add((tms.visitor_team, RDFS.domain, gms.Game))\n",
    "graph.add((tms.visitor_team, RDFS.range, tms.Team))\n",
    "graph.add((tms.visitor_team, RDF.type, RDF.Property))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_data=graph.serialize(format='turtle')\n",
    "fil=open(\"group07.ttl\", \"wb\")\n",
    "fil.write(graph_data)\n",
    "fil.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
