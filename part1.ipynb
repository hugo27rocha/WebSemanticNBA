{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project â€“ Phase 1 Group 07 Hugo Rocha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The database I chose was https://www.kaggle.com/nathanlauga/nba-games  <br>\n",
    "Which is a database that was collected to work on NBA games data. <br><br>\n",
    "\n",
    "The database has 5 datasets : <br>\n",
    "\n",
    "<b>games.csv :</b> all games from 2004 season to last update with the date, teams and some details like number of points, etc. <br>\n",
    "<b>games_details.csv :</b> details of games dataset, all statistics of players for a given game <br>\n",
    "<b>players.csv :</b> players details (name)  <br>\n",
    "<b>ranking.csv :</b> ranking of NBA given a day (split into west and east on CONFERENCE column <br>\n",
    "<b>teams.csv :</b> all teams of NBA<br><br>\n",
    "First I started working on the teams.csv file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n",
    "As for the usual imports I imported IRI baker which is a library that reliably creates valid (parts of) IRIs from strings (spaces are turned into underscores, etc.).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from csv import DictReader\n",
    "from rdflib import Dataset, URIRef, Literal, Namespace, RDF, RDFS, OWL, XSD, Graph\n",
    "from rdflib import Graph, URIRef, RDF, Literal\n",
    "from rdflib.namespace import FOAF, XSD, RDFS\n",
    "import pandas as pd\n",
    "from iribaker import to_iri"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TEAMS \n",
    "\n",
    "TEAM_ID -> ID of the team <br>\n",
    "TEAM_ID -> Minimum year of the team into NBA championship <br>\n",
    "MIN_YEAR -> Maximum year of the team into NBA championship <br>\n",
    "ABBREVIATION -> Abbreviation of team name<br>\n",
    "NICKNAME -> Team's nickname<br>\n",
    "YEARFOUNDED -> Founded Year<br>\n",
    "CITY -> Team's city<br>\n",
    "ARENA -> Team's stadium<br>\n",
    "ARENACAPACITY -> Capacity of the stadium<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "team_file = \"teams.csv\"\n",
    "with open(team_file,'r') as csvfile:\n",
    "    team_contents = [{k: v for k, v in row.items()}\n",
    "        for row in csv.DictReader(csvfile, skipinitialspace=True, quotechar='\"', delimiter=',')]\n",
    "\n",
    "tms = Namespace(\"http://www.di.fc.ul.pt/~nba/team#\")\n",
    "\n",
    "graph=Graph()\n",
    "graph.bind(\"tms\", tms)\n",
    "\n",
    "for s in team_contents:\n",
    "    tid= URIRef(tms+s[\"TEAM_ID\"])\n",
    "    lid= URIRef(tms+s[\"LEAGUE_ID\"])\n",
    "    Min_year=Literal(s[\"MIN_YEAR\"],datatype=XSD.int)\n",
    "    Max_year=Literal(s[\"MAX_YEAR\"],datatype=XSD.int)\n",
    "    abre = Literal(s['ABBREVIATION'], datatype=XSD['string'])\n",
    "    nick = URIRef(to_iri(tms+s[\"NICKNAME\"]))\n",
    "    nick_name =  Literal(s[\"NICKNAME\"], lang='en')\n",
    "    year_f=Literal(s[\"YEARFOUNDED\"],datatype=XSD.int)\n",
    "    City = URIRef(to_iri(tms+s[\"CITY\"]))\n",
    "    city_name =  Literal(s[\"CITY\"], lang='en')\n",
    "    Arena = URIRef(to_iri(tms+s[\"ARENA\"]))\n",
    "    arena_name =  Literal(s[\"ARENA\"], lang='en')\n",
    "    arenacapacity=Literal(s[\"ARENACAPACITY\"],datatype=XSD.int)\n",
    "  \n",
    "    graph.add((tid, RDF.type, tms.Team))\n",
    "    graph.add((tid, tms.team_id, tid))\n",
    "    graph.add((tid, tms.league, lid))\n",
    "    graph.add((tid, tms.min_year, Min_year))\n",
    "    graph.add((tid, tms.max_year, Max_year))\n",
    "    graph.add((tid, tms.abbreviation, abre))\n",
    "    graph.add((tid, tms.nickname, nick))\n",
    "    graph.add((nick, RDFS.label, nick_name))\n",
    "    graph.add((tid, tms.year_found, year_f))\n",
    "    graph.add((tid, tms.city, City))\n",
    "    graph.add((City, RDFS.label, city_name))\n",
    "    graph.add((tid, tms.arena, Arena))\n",
    "    graph.add((Arena, RDFS.label, arena_name))\n",
    "    graph.add((tid, tms.arena_capacity, arenacapacity))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PLAYERS\n",
    "PLAYER_NAME -> Player's name <br>\n",
    "TEAM_ID -> ID of the team <br>\n",
    "PLAYER_ID ->  ID of the player <br>\n",
    "SEASON -> Season<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('players.csv')\n",
    "\n",
    "data[\"player_id\"]  = data['PLAYER_ID'].apply(lambda x: str(x))\n",
    "data[\"season\"]  = data['SEASON'].apply(lambda x: str(x))\n",
    "data[\"roster_id\"] = data[\"player_id\"]  + \"_\" + data[\"season\"]\n",
    "del data[\"player_id\"]\n",
    "del data[\"season\"]\n",
    "data.to_csv('players.csv')\n",
    "\n",
    "pls = Namespace(\"http://www.di.fc.ul.pt/~nba/player#\")\n",
    "graph.bind(\"pls\", pls)\n",
    "\n",
    "team_file = \"players.csv\"\n",
    "with open(team_file,'r') as csvfile:\n",
    "    players_contents = [{k: v for k, v in row.items()}\n",
    "        for row in csv.DictReader(csvfile, skipinitialspace=True, quotechar='\"', delimiter=',')]\n",
    "\n",
    "for p in players_contents:\n",
    "    rid = URIRef(pls+p[\"roster_id\"])\n",
    "    pid = URIRef(pls+p[\"PLAYER_ID\"])\n",
    "    tid  = URIRef(tms+p[\"TEAM_ID\"])\n",
    "    Season=Literal(p[\"SEASON\"],datatype=XSD.int)\n",
    "    player = URIRef(to_iri(pls+p[\"PLAYER_NAME\"]))\n",
    "    player_name =  Literal(p[\"PLAYER_NAME\"], lang='en')  \n",
    "    \n",
    "    graph.add((rid, RDF.type, pls.Player))\n",
    "    graph.add((rid, pls.player_id, pid))\n",
    "    graph.add((rid, tms.team, tid))\n",
    "    graph.add((rid, pls.season, Season))\n",
    "    graph.add((rid, pls.Name, player))\n",
    "    graph.add((player, RDFS.label, player_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Games\n",
    "GAME_DATE_EST -> Game's date <br>\n",
    "GAME_ID -> ID of the game  <br>\n",
    "HOME_TEAM_ID -> ID of the home team <br>\n",
    "VISITOR_TEAM_ID -> ID of the visitor team <br>\n",
    "SEASON -> Season when the game occured <br>\n",
    "PTS_home -> Number of points scored by home team <br> \n",
    "PTS_away -> Number of points scored by away team <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "gms = Namespace(\"http://www.di.fc.ul.pt/~nba/games#\")\n",
    "graph.bind(\"gms\", gms)\n",
    "\n",
    "rank_file = \"games.csv\"\n",
    "with open(rank_file,'r') as csvfile:\n",
    "    game_contents = [{k: v for k, v in row.items()}\n",
    "        for row in csv.DictReader(csvfile, skipinitialspace=True, quotechar='\"', delimiter=',')]\n",
    "\n",
    "     \n",
    "for g in game_contents:\n",
    "       \n",
    "    game_id = URIRef(gms+g[\"GAME_ID\"])  \n",
    "    Game_Date=Literal(g[\"GAME_DATE_EST\"],datatype=XSD.date)\n",
    "    Season=Literal(g[\"SEASON\"],datatype=XSD.int)\n",
    "    Home= URIRef(tms+g[\"HOME_TEAM_ID\"]) \n",
    "    Visitor= URIRef(tms+g[\"VISITOR_TEAM_ID\"])\n",
    "    points_home=Literal(g[\"PTS_home\"],datatype=XSD.int)\n",
    "    points_away=Literal(g[\"PTS_away\"],datatype=XSD.int)\n",
    "    \n",
    "    graph.add((game_id, RDF.type, gms.Game))\n",
    "    graph.add((game_id, gms.game_id, game_id))\n",
    "    graph.add((game_id, gms.date, Game_Date))\n",
    "    graph.add((game_id, gms.season, Season))\n",
    "    graph.add((game_id, tms.home_team, Home))\n",
    "    graph.add((game_id, tms.visitor_team, Visitor))\n",
    "    graph.add((game_id, gms.Points_home, points_home))\n",
    "    graph.add((game_id, gms.Points_away, points_away))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ranking\n",
    "TEAM_ID -> ID of the team <br>\n",
    "SEASON_ID -> Season<br>\n",
    "STANDINGSDATE -> Standings date<br>\n",
    "CONFERENCE -> Conference (west or east)<br>\n",
    "TEAM -> Team name<br>\n",
    "G -> Number of games played on the season<br>\n",
    "W -> Number of winning games on the season<br>\n",
    "L -> Number of loosing games on the season<br>\n",
    "W_PCT -> Win %\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('ranking.csv')\n",
    "data[\"team_idd\"]  = data['TEAM_ID'].apply(lambda x: str(x))\n",
    "data[\"date\"]  = data['STANDINGSDATE'].apply(lambda x: str(x))\n",
    "data[\"ranking_id\"] = data[\"team_idd\"]  + \"_\"+ data[\"date\"]\n",
    "del data[\"team_idd\"]\n",
    "del data[\"date\"]\n",
    "data.to_csv('ranking.csv')\n",
    "\n",
    "\n",
    "rks = Namespace(\"http://www.di.fc.ul.pt/~nba/ranking#\")\n",
    "graph.bind(\"rks\", rks)\n",
    "\n",
    "rank_file = \"ranking.csv\"\n",
    "with open(rank_file,'r') as csvfile:\n",
    "    ranking_contents = [{k: v for k, v in row.items()}\n",
    "        for row in csv.DictReader(csvfile, skipinitialspace=True, quotechar='\"', delimiter=',')]\n",
    "\n",
    "\n",
    "for r in ranking_contents:\n",
    "       \n",
    "    rank_id = URIRef(rks+r[\"ranking_id\"])\n",
    "    tid= URIRef(tms+r[\"TEAM_ID\"]) \n",
    "    Season=Literal(r[\"SEASON_ID\"],datatype=XSD.int)\n",
    "    Date=Literal(r[\"STANDINGSDATE\"],datatype=XSD.date)\n",
    "    conference = URIRef(rks+r[\"CONFERENCE\"])\n",
    "    conference_name =  Literal(r[\"CONFERENCE\"], lang='en')  \n",
    "    team = URIRef(to_iri(rks+r[\"TEAM\"]))\n",
    "    team_name =  Literal(r[\"TEAM\"], lang='en')  \n",
    "    Games=Literal(r[\"G\"],datatype=XSD.int)\n",
    "    Wins=Literal(r[\"W\"],datatype=XSD.int)\n",
    "    Loses=Literal(r[\"L\"],datatype=XSD.int)\n",
    "    WL=Literal(r[\"W_PCT\"],datatype=XSD.decimal)\n",
    "    \n",
    "    graph.add((rank_id, RDF.type, rks.Ranking))\n",
    "    graph.add((rank_id, tms.team, tid))\n",
    "    graph.add((rank_id, rks.season, Season))\n",
    "    graph.add((rank_id, rks.date, Date))\n",
    "    graph.add((rank_id, rks.Conference, conference))\n",
    "    graph.add((conference, RDFS.label, conference_name))\n",
    "    graph.add((rank_id, rks.Team, team))\n",
    "    graph.add((team, RDFS.label, team_name))\n",
    "    graph.add((rank_id, rks.games, Games))\n",
    "    graph.add((rank_id, rks.wins, Wins))\n",
    "    graph.add((rank_id, rks.loses, Loses))\n",
    "    graph.add((rank_id, rks.W_PCT, WL))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Game Details\n",
    "o game_details.csv tem 75.36 MB o que demorou muito tempo a processar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdt = Namespace(\"http://www.di.fc.ul.pt/~nba/games_details#\")\n",
    "graph.bind(\"gdt\", gdt)\n",
    "\n",
    "data = pd.read_csv('games_details.csv')\n",
    "\n",
    "data[\"game_id\"]  = data['GAME_ID'].apply(lambda x: str(x))\n",
    "data[\"player_id\"]  = data['PLAYER_ID'].apply(lambda x: str(x))\n",
    "data[\"player_game\"] = data[\"game_id\"]  + \"_\" + data[\"player_id\"]\n",
    "del data[\"game_id\"]\n",
    "del data[\"player_id\"]\n",
    "data.to_csv('game_details.csv')\n",
    "\n",
    "rank_file = \"game_details.csv\"\n",
    "with open(rank_file,'r') as csvfile:\n",
    "    game_details_contents = [{k: v for k, v in row.items()}\n",
    "        for row in csv.DictReader(csvfile, skipinitialspace=True, quotechar='\"', delimiter=',')]\n",
    "\n",
    "\n",
    "for g in game_details_contents:\n",
    "       \n",
    "    player_game_id = URIRef(gdt+g[\"player_game\"])\n",
    "    gid= URIRef(gms+g[\"GAME_ID\"]) \n",
    "    tid= URIRef(tms+g[\"TEAM_ID\"]) \n",
    "    abre = Literal(g['TEAM_ABBREVIATION'], datatype=XSD['string'])\n",
    "    City = URIRef(to_iri(tms+g[\"TEAM_CITY\"]))\n",
    "    city_name =  Literal(g[\"TEAM_CITY\"], lang='en')\n",
    "    pid= URIRef(pls+g[\"PLAYER_ID\"]) \n",
    "    player = URIRef(to_iri(pls+g[\"PLAYER_NAME\"]))\n",
    "    player_name =  Literal(g[\"PLAYER_NAME\"], lang='en') \n",
    "    \n",
    "    graph.add((player_game_id, RDF.type, gdt.Game_Details))\n",
    "    graph.add((player_game_id, gms.game, gid))\n",
    "    graph.add((player_game_id, tms.team, tid))\n",
    "    graph.add((player_game_id, tms.abbreviation, abre))\n",
    "    graph.add((player_game_id, tms.city, City))\n",
    "    graph.add((City, RDFS.label, city_name))\n",
    "    graph.add((player_game_id, pls.player_id, pid))\n",
    "    graph.add((player_game_id, pls.Name, player))\n",
    "    graph.add((player, RDFS.label, player_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_data=graph.serialize(format='turtle')\n",
    "fil=open(\"group07.ttl\", \"wb\")\n",
    "fil.write(graph_data)\n",
    "fil.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sparql \n",
    "I run my queries in Apache Jena Fuseki here are the code and results\n",
    "## Query 1\n",
    "Em que equipas jogou o jogador Lebron James durante a sua carreira?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "?season\t?nickname\n",
      "\"2009\"^^<http://www.w3.org/2001/XMLSchema#int>\t<http://www.di.fc.ul.pt/~nba/team#Cavaliers>\n",
      "\"2010\"^^<http://www.w3.org/2001/XMLSchema#int>\t<http://www.di.fc.ul.pt/~nba/team#Heat>\n",
      "\"2011\"^^<http://www.w3.org/2001/XMLSchema#int>\t<http://www.di.fc.ul.pt/~nba/team#Heat>\n",
      "\"2012\"^^<http://www.w3.org/2001/XMLSchema#int>\t<http://www.di.fc.ul.pt/~nba/team#Heat>\n",
      "\"2013\"^^<http://www.w3.org/2001/XMLSchema#int>\t<http://www.di.fc.ul.pt/~nba/team#Heat>\n",
      "\"2014\"^^<http://www.w3.org/2001/XMLSchema#int>\t<http://www.di.fc.ul.pt/~nba/team#Cavaliers>\n",
      "\"2015\"^^<http://www.w3.org/2001/XMLSchema#int>\t<http://www.di.fc.ul.pt/~nba/team#Cavaliers>\n",
      "\"2016\"^^<http://www.w3.org/2001/XMLSchema#int>\t<http://www.di.fc.ul.pt/~nba/team#Cavaliers>\n",
      "\"2017\"^^<http://www.w3.org/2001/XMLSchema#int>\t<http://www.di.fc.ul.pt/~nba/team#Cavaliers>\n",
      "\"2018\"^^<http://www.w3.org/2001/XMLSchema#int>\t<http://www.di.fc.ul.pt/~nba/team#Lakers>\n",
      "\"2019\"^^<http://www.w3.org/2001/XMLSchema#int>\t<http://www.di.fc.ul.pt/~nba/team#Lakers>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from SPARQLWrapper import SPARQLWrapper, XML, TSV\n",
    "\n",
    "\n",
    "\n",
    "sparql = SPARQLWrapper(\"http://localhost:3030/FWS07/query\")\n",
    "query=\"\"\"\n",
    "\n",
    "prefix tm: <http://def.seegrid.csiro.au/isotc211/iso19108/2002/temporal#>\n",
    "prefix gms: <http://www.di.fc.ul.pt/~nba/games#> \n",
    "prefix pls: <http://www.di.fc.ul.pt/~nba/player#> \n",
    "prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#> \n",
    "prefix rks: <http://www.di.fc.ul.pt/~nba/ranking#> \n",
    "prefix tms: <http://www.di.fc.ul.pt/~nba/team#> \n",
    "prefix xsd: <http://www.w3.org/2001/XMLSchema#> \n",
    "\n",
    "SELECT ?season ?nickname\n",
    "WHERE {\n",
    "  ?p a tms:Team .\n",
    "  ?p tms:team_id ?team .\n",
    "  ?p tms:nickname ?nickname .\n",
    "  ?s a pls:Player .\n",
    "  ?s pls:Name pls:LeBron_James.\n",
    "  ?s pls:season ?season .\n",
    "  ?s tms:team ?team .\n",
    "}\n",
    " ORDER BY ?season\n",
    "       \n",
    "\"\"\"\n",
    "sparql.setQuery(query)\n",
    "\n",
    "sparql.setReturnFormat(TSV)\n",
    "results = sparql.query().convert().decode(\"utf-8\")\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query 2\n",
    "NÃºmero de VitÃ³rias da equipa em que o Lebron James jogava ao longo do mÃªs de Dezembro de 2010\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "?date\t?w\n",
      "\"2010-12-01\"^^<http://www.w3.org/2001/XMLSchema#date>\t\"11\"^^<http://www.w3.org/2001/XMLSchema#int>\n",
      "\"2010-12-02\"^^<http://www.w3.org/2001/XMLSchema#date>\t\"12\"^^<http://www.w3.org/2001/XMLSchema#int>\n",
      "\"2010-12-03\"^^<http://www.w3.org/2001/XMLSchema#date>\t\"12\"^^<http://www.w3.org/2001/XMLSchema#int>\n",
      "\"2010-12-04\"^^<http://www.w3.org/2001/XMLSchema#date>\t\"13\"^^<http://www.w3.org/2001/XMLSchema#int>\n",
      "\"2010-12-05\"^^<http://www.w3.org/2001/XMLSchema#date>\t\"13\"^^<http://www.w3.org/2001/XMLSchema#int>\n",
      "\"2010-12-06\"^^<http://www.w3.org/2001/XMLSchema#date>\t\"14\"^^<http://www.w3.org/2001/XMLSchema#int>\n",
      "\"2010-12-07\"^^<http://www.w3.org/2001/XMLSchema#date>\t\"14\"^^<http://www.w3.org/2001/XMLSchema#int>\n",
      "\"2010-12-08\"^^<http://www.w3.org/2001/XMLSchema#date>\t\"15\"^^<http://www.w3.org/2001/XMLSchema#int>\n",
      "\"2010-12-09\"^^<http://www.w3.org/2001/XMLSchema#date>\t\"15\"^^<http://www.w3.org/2001/XMLSchema#int>\n",
      "\"2010-12-10\"^^<http://www.w3.org/2001/XMLSchema#date>\t\"16\"^^<http://www.w3.org/2001/XMLSchema#int>\n",
      "\"2010-12-11\"^^<http://www.w3.org/2001/XMLSchema#date>\t\"17\"^^<http://www.w3.org/2001/XMLSchema#int>\n",
      "\"2010-12-12\"^^<http://www.w3.org/2001/XMLSchema#date>\t\"17\"^^<http://www.w3.org/2001/XMLSchema#int>\n",
      "\"2010-12-13\"^^<http://www.w3.org/2001/XMLSchema#date>\t\"18\"^^<http://www.w3.org/2001/XMLSchema#int>\n",
      "\"2010-12-14\"^^<http://www.w3.org/2001/XMLSchema#date>\t\"18\"^^<http://www.w3.org/2001/XMLSchema#int>\n",
      "\"2010-12-15\"^^<http://www.w3.org/2001/XMLSchema#date>\t\"19\"^^<http://www.w3.org/2001/XMLSchema#int>\n",
      "\"2010-12-16\"^^<http://www.w3.org/2001/XMLSchema#date>\t\"19\"^^<http://www.w3.org/2001/XMLSchema#int>\n",
      "\"2010-12-17\"^^<http://www.w3.org/2001/XMLSchema#date>\t\"20\"^^<http://www.w3.org/2001/XMLSchema#int>\n",
      "\"2010-12-18\"^^<http://www.w3.org/2001/XMLSchema#date>\t\"21\"^^<http://www.w3.org/2001/XMLSchema#int>\n",
      "\"2010-12-19\"^^<http://www.w3.org/2001/XMLSchema#date>\t\"21\"^^<http://www.w3.org/2001/XMLSchema#int>\n",
      "\"2010-12-20\"^^<http://www.w3.org/2001/XMLSchema#date>\t\"21\"^^<http://www.w3.org/2001/XMLSchema#int>\n",
      "\"2010-12-21\"^^<http://www.w3.org/2001/XMLSchema#date>\t\"21\"^^<http://www.w3.org/2001/XMLSchema#int>\n",
      "\"2010-12-22\"^^<http://www.w3.org/2001/XMLSchema#date>\t\"21\"^^<http://www.w3.org/2001/XMLSchema#int>\n",
      "\"2010-12-23\"^^<http://www.w3.org/2001/XMLSchema#date>\t\"22\"^^<http://www.w3.org/2001/XMLSchema#int>\n",
      "\"2010-12-24\"^^<http://www.w3.org/2001/XMLSchema#date>\t\"22\"^^<http://www.w3.org/2001/XMLSchema#int>\n",
      "\"2010-12-25\"^^<http://www.w3.org/2001/XMLSchema#date>\t\"23\"^^<http://www.w3.org/2001/XMLSchema#int>\n",
      "\"2010-12-26\"^^<http://www.w3.org/2001/XMLSchema#date>\t\"23\"^^<http://www.w3.org/2001/XMLSchema#int>\n",
      "\"2010-12-27\"^^<http://www.w3.org/2001/XMLSchema#date>\t\"23\"^^<http://www.w3.org/2001/XMLSchema#int>\n",
      "\"2010-12-28\"^^<http://www.w3.org/2001/XMLSchema#date>\t\"24\"^^<http://www.w3.org/2001/XMLSchema#int>\n",
      "\"2010-12-29\"^^<http://www.w3.org/2001/XMLSchema#date>\t\"25\"^^<http://www.w3.org/2001/XMLSchema#int>\n",
      "\"2010-12-30\"^^<http://www.w3.org/2001/XMLSchema#date>\t\"25\"^^<http://www.w3.org/2001/XMLSchema#int>\n",
      "\"2010-12-31\"^^<http://www.w3.org/2001/XMLSchema#date>\t\"25\"^^<http://www.w3.org/2001/XMLSchema#int>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sparql = SPARQLWrapper(\"http://localhost:3030/FWS07/query\")\n",
    "query=\"\"\"\n",
    "\n",
    "PREFIX re: <http://www.w3.org/2000/10/swap/reason#>\n",
    "PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>\n",
    "prefix tm: <http://def.seegrid.csiro.au/isotc211/iso19108/2002/temporal#>\n",
    "prefix gms: <http://www.di.fc.ul.pt/~nba/games#> \n",
    "prefix pls: <http://www.di.fc.ul.pt/~nba/player#> \n",
    "prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#> \n",
    "prefix rks: <http://www.di.fc.ul.pt/~nba/ranking#> \n",
    "prefix tms: <http://www.di.fc.ul.pt/~nba/team#> \n",
    "prefix xsd: <http://www.w3.org/2001/XMLSchema#> \n",
    "\n",
    "\n",
    "SELECT ?date ?w \n",
    "WHERE {\n",
    "\n",
    "  ?p a tms:Team .\n",
    "  ?p tms:team_id ?team .\n",
    "  ?s a pls:Player .\n",
    "  ?s pls:Name pls:LeBron_James.\n",
    "  ?s pls:season ?se .\n",
    "  ?s tms:team ?team .\n",
    "  ?r a rks:Ranking .\n",
    "  ?r tms:team ?team .\n",
    "  ?r rks:date ?date . \n",
    "  ?r rks:wins ?w\n",
    "  FILTER ( ?date >= \"2010-12-01\"^^xsd:date && ?date <= \"2010-12-31\"^^xsd:date  &&  ?se = 2010)\n",
    " }\n",
    "ORDER BY ?date\n",
    "       \n",
    "\"\"\"\n",
    "sparql.setQuery(query)\n",
    "\n",
    "sparql.setReturnFormat(TSV)\n",
    "results = sparql.query().convert().decode(\"utf-8\")\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query 3\n",
    "Todos os Jogos em que a equipa da casa marcou mais de 140 pontos\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "?team\t?date\t?points\n",
      "<http://www.di.fc.ul.pt/~nba/team#Celtics>\t\"2020-02-13\"^^<http://www.w3.org/2001/XMLSchema#date>\t\"141\"^^<http://www.w3.org/2001/XMLSchema#int>\n",
      "<http://www.di.fc.ul.pt/~nba/team#Hawks>\t\"2020-02-28\"^^<http://www.w3.org/2001/XMLSchema#date>\t\"141\"^^<http://www.w3.org/2001/XMLSchema#int>\n",
      "<http://www.di.fc.ul.pt/~nba/team#Timberwolves>\t\"2020-02-08\"^^<http://www.w3.org/2001/XMLSchema#date>\t\"142\"^^<http://www.w3.org/2001/XMLSchema#int>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sparql = SPARQLWrapper(\"http://localhost:3030/FWS07/query\")\n",
    "query=\"\"\"\n",
    "\n",
    "PREFIX tm: <http://def.seegrid.csiro.au/isotc211/iso19108/2002/temporal#>\n",
    "PREFIX gm: <http://def.seegrid.csiro.au/isotc211/iso19107/2003/geometry#>\n",
    "prefix gms: <http://www.di.fc.ul.pt/~nba/games#> \n",
    "prefix pls: <http://www.di.fc.ul.pt/~nba/player#> \n",
    "prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#> \n",
    "prefix rks: <http://www.di.fc.ul.pt/~nba/ranking#> \n",
    "prefix tms: <http://www.di.fc.ul.pt/~nba/team#> \n",
    "prefix xsd: <http://www.w3.org/2001/XMLSchema#> \n",
    "\n",
    "SELECT ?team ?date ?points \n",
    "WHERE {\n",
    "  \n",
    "  ?game a gms:Game .\n",
    "  ?game gms:Points_home ?points .\n",
    "  ?game gms:date ?date .\n",
    "  ?game tms:home_team ?l .\n",
    "  ?t a tms:Team .\n",
    "  ?t tms:team_id ?l .\n",
    "  ?t tms:nickname ?team .\n",
    "  FILTER (?points > 140) \n",
    "       }\n",
    "  ORDER BY ?points  \n",
    "       \n",
    "\"\"\"\n",
    "sparql.setQuery(query)\n",
    "\n",
    "sparql.setReturnFormat(TSV)\n",
    "results = sparql.query().convert().decode(\"utf-8\")\n",
    "print(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
